{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "import collections as col\n",
    "import spacy \n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonctions communes à tous les types de journaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_soup(url):\n",
    "    \"\"\"\n",
    "        The function parse the page with beautifulsoup\n",
    "        @param :  string containing the url of the rss feed\n",
    "        @return : object containing the parse page\n",
    "    \"\"\"\n",
    "    try:\n",
    "        req = requests.get(url)\n",
    "        data = req.text\n",
    "        soup = bs4.BeautifulSoup(data, \"lxml\")\n",
    "        return(soup)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        Remove the inapropriate caracters/words in order to clean the content\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return nlp(text).text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def create_json_file(articles,name,path):\n",
    "    \"\"\"\n",
    "        Transform the list containing info on articles into  json file\n",
    "        @param articles : all articles scraped\n",
    "        @param i : the rough article id\n",
    "        @param path : path where the json files are stored\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_creation = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        df = pd.DataFrame(articles)\n",
    "        filename = 'art_'+date_creation+'_' + name+'.json'\n",
    "        with open(path + filename, 'w', encoding='utf-8') as file:\n",
    "            df.to_json(file, orient='index',force_ascii=False) \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journal de l'environnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_url_articles_jdle(soup_link_website, website_link, nb_max_pages):\n",
    "    \"\"\"\n",
    "        Based on the links passed in parameter, we get the url articles of the website\n",
    "        @return :  A list of links of articles\n",
    "    \"\"\"\n",
    "    try:\n",
    "        link_articles = []\n",
    "        key_words = ['plastique','microplastique']\n",
    "        \n",
    "        # Get all pages of the website\n",
    "        for i in tqdm_notebook(range(1,nb_max_pages)):\n",
    "            # Get all articles in a page\n",
    "            soup = parse_soup(soup_link_website + '/' + str(i))\n",
    "\n",
    "            #Select only the link of the articles\n",
    "            for article_link in soup.find_all('a'):\n",
    "                if article_link.get(\"href\") != None and '#' not in article_link.get(\"href\") and any(word in article_link.get(\"href\").lower() for word in key_words):\n",
    "                    new_article = website_link + article_link.get(\"href\")\n",
    "                    link_articles.append(new_article)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return list(set(link_articles))\n",
    "\n",
    "def get_info_articles_jdle(link_articles):\n",
    "    \"\"\"\n",
    "        We get the content of the different articles\n",
    "        @return : dictionnary with info on articles\n",
    "    \"\"\"\n",
    "    new_articles = []\n",
    "    for index,link in tqdm_notebook(enumerate(link_articles)):\n",
    "        # Initilialize variables\n",
    "        contents = []\n",
    "        description = title = pub_date = authors = \"\"\n",
    "\n",
    "        # Get the content of the page relative to an article\n",
    "        soup = parse_soup(link_articles)\n",
    "\n",
    "        Get the description\n",
    "        if soup.find('strong') != None:\n",
    "            description= soup.find('strong').text\n",
    "\n",
    "        # Get title\n",
    "        if soup.find('h1', {'class':\"articleTitre\"}) != None:\n",
    "                title=soup.find('h1', {'class':\"articleTitre\"}).text\n",
    "\n",
    "        # Get the authors and publication_date\n",
    "        posssible_authors = [soup.find('div',{\"class\":\"articleHautPageAuthor\"}),soup.find(\"span\",{\"class\":\"regular11px\"})]\n",
    "        for author in posssible_authors:\n",
    "            if author != None:\n",
    "                authors = author.text.split('par')[1] # get only the author\n",
    "                pub_date = author.text.replace(' ','').split('par')[0][2:] # get only the date\n",
    "\n",
    "        # Get the date at the right format\n",
    "        dictio_month = {'janvier':'01','février':'02','mars':'03','avril':'04','mai':'05','juin':'06','juillet':'07','août':'08','septembre':'09','octobre':'10','novembre':'11','décembre':'12'}\n",
    "        year = pub_date[-4:]\n",
    "        day = pub_date[0:2]\n",
    "        month = dictio_month[pub_date[2:len(pub_date)-4]]\n",
    "        pub_date = str(year+'/'+month+'/'+day)\n",
    "\n",
    "        # Get contents   \n",
    "        for bal in soup.find_all(\"p\", {\"class\":\"MsoNormal\"}):\n",
    "            for cont in bal.find_all('span'):\n",
    "                contents.append(cont.text)\n",
    "            \n",
    "        # Clean the string variable\n",
    "        contents = clean_text(' '.join(contents))\n",
    "        title = clean_text(title)\n",
    "        description = clean_text(description)\n",
    "        authors = clean_text(authors)\n",
    "        \n",
    "        new_articles.append({\n",
    "            \"id_article\":index,\n",
    "            \"link\":link,\n",
    "            \"title\":title,\n",
    "            \"description\":description,\n",
    "            \"content\":contents,\n",
    "            \"authors\":authors,\n",
    "            \"publication_date\":pub_date\n",
    "        })\n",
    "    return new_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> On se concentre sur les thèmes eau, déchets et climat proposés par le journal de l'environnement \n",
    "dans le but de récupérer les liens qui nous sont utiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes = [\"eau\",\"dechets\",\"climat\"]\n",
    "nb_pages = [370,260,180]\n",
    "link= \"http://www.journaldelenvironnement.net\"\n",
    "path = '../data/links/url_articles_jdle.csv'\n",
    "\n",
    "link_articles_jdle = []\n",
    "for i,theme in tqdm_notebook(enumerate(themes)):\n",
    "    link_articles_jdle.append(get_url_articles_jdle(link+'/'+themes[i],link,nb_pages[i]))\n",
    "    \n",
    "link_articles_jdle = list(set(link_articles_jdle[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada0403edde34df1a9e9fcc344d4bede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No connection adapters were found for '['http://www.journaldelenvironnement.net/article/micro-plastiques-une-pollution-generalisee-a-la-surface-des-oceans,47764', 'http://www.journaldelenvironnement.net/article/la-concentration-des-dechets-plastique-a-explose-dans-le-pacifique,28952', 'http://www.journaldelenvironnement.net/article/vers-une-reduction-de-80-de-l-utilisation-des-sacs-plastique-en-europe,43835', 'http://www.journaldelenvironnement.net/article/la-nouvelle-faune-de-nos-rivieres-est-en-plastique,75825', 'http://www.journaldelenvironnement.net/article/en-fondant-la-banquise-pourrait-liberer-des-plastiques,46411', 'http://www.journaldelenvironnement.net/article/continents-de-plastique-par-ici-la-sortie,70368', 'http://www.journaldelenvironnement.net/article/les-moules-de-la-braderie-de-lille-ont-des-relents-de-plastique,36247', 'http://www.journaldelenvironnement.net/article/la-mediterranee-est-asphyxiee-aux-dechets-plastique,92098', 'http://www.journaldelenvironnement.net/article/sacs-plastique-interdictions-et-taxes-se-multiplient-aux-etats-unis,45414', 'http://www.journaldelenvironnement.net/article/bruxelles-s-attaque-aux-objets-en-plastique-jetables,91552', 'http://www.journaldelenvironnement.net/article/dechets-plastique-une-synthese-des-impacts-est-necessaire,57958', 'http://www.journaldelenvironnement.net/article/plastiques-en-mer-la-sante-des-huitres-s-en-ressent,66678', 'http://www.journaldelenvironnement.net/article/accord-europeen-sur-la-disparition-des-sacs-en-plastique-legers,52606', 'http://www.journaldelenvironnement.net/article/les-deputes-mettent-la-fin-des-plastiques-jetables-a-leur-sauce,93694', 'http://www.journaldelenvironnement.net/article/oceans-le-barrage-flottant-n-arrete-pas-les-plastiques,95386', 'http://www.journaldelenvironnement.net/article/plastiques-marins-le-monstre-du-pacifique-grossit-a-vue-d-il,91033', 'http://www.journaldelenvironnement.net/article/des-multinationales-s-allient-contre-les-dechets-plastiques,95698', 'http://www.journaldelenvironnement.net/article/produits-de-soins-l-illinois-vote-la-fin-des-microbilles-de-plastique,46918', 'http://www.journaldelenvironnement.net/article/plastique-finis-les-coton-tiges-et-les-exfoliants-au-plastique,75711', 'http://www.journaldelenvironnement.net/article/les-dechets-plastique-aussi-nombreux-dans-les-grands-fonds-marins,45679', 'http://www.journaldelenvironnement.net/article/5-000-milliards-de-debris-plastique-sur-les-oceans,53356', 'http://www.journaldelenvironnement.net/article/des-micro-plastiques-les-poissons-en-ont-plein-les-branchies,48493', 'http://www.journaldelenvironnement.net/article/la-future-taxe-anglaise-sur-les-sacs-plastique-vivement-critiquee,42580', 'http://www.journaldelenvironnement.net/article/les-villes-zero-plastique-essaiment-au-royaume-uni,92887', 'http://www.journaldelenvironnement.net/article/plastique-un-laboratoire-cree-par-hasard-une-enzyme-gloutonne,91360', 'http://www.journaldelenvironnement.net/article/des-microplastiques-marins-tres-terre-a-terre,71661', 'http://www.journaldelenvironnement.net/article/bientot-la-fin-a-la-carte-des-sacs-plastique-en-europe,38204', 'http://www.journaldelenvironnement.net/article/du-plastique-dans-9-des-poissons-du-pacifique,23961', 'http://www.journaldelenvironnement.net/article/dans-les-rivieres-francaises-aussi-les-poissons-mangent-des-microplastiques,52759', 'http://www.journaldelenvironnement.net/article/vous-preferez-les-moules-avec-ou-sans-plastique,92125', 'http://www.journaldelenvironnement.net/article/premiere-cartographie-de-la-pollution-plastique-des-oceans,81606', 'http://www.journaldelenvironnement.net/article/londres-interdit-les-microbilles-en-plastique-des-cosmetiques,74241', 'http://www.journaldelenvironnement.net/article/les-sacs-en-plastique-desertent-la-californie,49499', 'http://www.journaldelenvironnement.net/article/les-bioplastiques-une-fausse-bonne-solution,70659', 'http://www.journaldelenvironnement.net/article/bruxelles-consulte-sur-la-fin-de-vie-des-sacs-en-plastique,23236', 'http://www.journaldelenvironnement.net/article/plastique-des-experts-demandent-l-interdiction-des-microbilles,62172', 'http://www.journaldelenvironnement.net/article/la-nouvelle-caledonie-interdit-les-plastiques-jetables,95461', 'http://www.journaldelenvironnement.net/article/les-cotes-grecques-pantheon-des-dechets-plastiques,55252', 'http://www.journaldelenvironnement.net/article/les-microplastiques-alterent-les-fonctions-des-ecosystemes-marins,40042', 'http://www.journaldelenvironnement.net/article/l-odeur-des-dechets-plastique-marins-attire-les-poissons,85486', 'http://www.journaldelenvironnement.net/article/adidas-va-recycler-des-debris-plastiques-des-oceans,57868', 'http://www.journaldelenvironnement.net/article/la-tamise-elle-aussi-charrie-des-dechets-plastique,41221', 'http://www.journaldelenvironnement.net/article/du-plastique-dans-l-estomac-des-coraux,55837', 'http://www.journaldelenvironnement.net/article/la-commission-europeenne-s-attaque-aux-plastiques,89668', 'http://www.journaldelenvironnement.net/article/90-ong-imaginent-un-monde-sans-plastique,74559', 'http://www.journaldelenvironnement.net/article/des-microplastiques-aux-confins-de-l-antarctique,92062', 'http://www.journaldelenvironnement.net/article/le-plastique-est-partout-le-recyclage-quasiment-nulle-part,84823', 'http://www.journaldelenvironnement.net/article/le-kenya-sanctionne-lourdement-l-usage-des-sacs-plastique,85630', 'http://www.journaldelenvironnement.net/article/extraire-les-plastiques-flottants-une-goutte-d-eau-dans-l-ocean,93520', 'http://www.journaldelenvironnement.net/article/les-eaux-australiennes-aussi-sont-saturees-de-plastiques,39850', 'http://www.journaldelenvironnement.net/article/plastiques-la-pollution-marine-coute-au-moins-10-md,47376', 'http://www.journaldelenvironnement.net/article/dechets-plastiques-marins-le-phenomene-s-emballe,55501', 'http://www.journaldelenvironnement.net/article/les-oiseaux-de-mer-attires-par-l-odeur-des-micro-plastiques,76527', 'http://www.journaldelenvironnement.net/article/dechets-plastique-et-en-plus-ils-renforcent-l-effet-de-serre,93187', 'http://www.journaldelenvironnement.net/article/forte-concentration-de-particules-plastiques-dans-les-grands-lacs,34573', 'http://www.journaldelenvironnement.net/article/vehicules-par-les-insectes-les-microplastiques-contaminent-aussi-l-air,93700', 'http://www.journaldelenvironnement.net/article/oceans-les-trois-quarts-des-plastiques-rejetes-par-20-fleuves,83548', 'http://www.journaldelenvironnement.net/article/la-norvege-refuse-d-abandonner-les-sacs-en-plastique,62703', 'http://www.journaldelenvironnement.net/article/le-lac-de-garde-macropollue-par-les-plastiques,37480', 'http://www.journaldelenvironnement.net/article/les-deputes-britanniques-veulent-supprimer-les-microbilles-en-plastique,73860', 'http://www.journaldelenvironnement.net/article/les-poissons-du-channel-mangent-aussi-du-plastique,32803', 'http://www.journaldelenvironnement.net/article/les-recifs-coralliens-malades-des-plastiques,90070', 'http://www.journaldelenvironnement.net/article/thon-et-espadon-a-la-sauce-plastique,60813', 'http://www.journaldelenvironnement.net/article/du-plastique-cache-dans-l-eau-du-robinet,85864', 'http://www.journaldelenvironnement.net/article/ue-la-fin-des-sacs-plastique-au-bon-vouloir-des-etats-membres,38690', 'http://www.journaldelenvironnement.net/article/microplastiques-les-larves-de-poissons-plus-vulnerables,71076', 'http://www.journaldelenvironnement.net/article/en-mediterranee-deux-tiers-des-oiseaux-pelagiques-ingerent-du-plastique,43454', 'http://www.journaldelenvironnement.net/article/90-des-bouteilles-d-eau-contiennent-du-plastique,90919', 'http://www.journaldelenvironnement.net/article/la-mediterranee-envahie-par-les-micro-dechets-de-plastique,20830', 'http://www.journaldelenvironnement.net/article/la-mediterranee-entre-pcb-tbt-et-microplastiques,71403', 'http://www.journaldelenvironnement.net/article/la-californie-va-interdire-les-microbilles-en-plastique,62862', 'http://www.journaldelenvironnement.net/article/ou-sont-passes-les-dechets-plastique-de-l-atlantique,18682', 'http://www.journaldelenvironnement.net/article/microbilles-de-plastique-le-royaume-uni-evoque-leur-interdiction,70152', 'http://www.journaldelenvironnement.net/article/microplastique-un-risque-alimentaire-inconnu,71961', 'http://www.journaldelenvironnement.net/article/l-ecosse-va-interdire-les-cotons-tiges-en-plastique,89563', 'http://www.journaldelenvironnement.net/article/micro-plastiques-plus-de-800-especes-marines-en-danger,77370', 'http://www.journaldelenvironnement.net/article/microplastiques-vers-une-interdiction-partielle-de-l-ue-en-2020,95770', 'http://www.journaldelenvironnement.net/article/les-pecheurs-europeens-partent-a-la-peche-aux-plastiques,23023', 'http://www.journaldelenvironnement.net/article/nanoplastiques-a-la-mer,88906', 'http://www.journaldelenvironnement.net/article/plastiques-en-mer-mieux-vaut-agir-pres-des-cotes,66252', 'http://www.journaldelenvironnement.net/article/dans-l-atlantique-du-nord-ouest-3-poissons-sur-4-ont-ingere-du-plastique,90589', 'http://www.journaldelenvironnement.net/article/monaco-interdit-les-pailles-en-plastique,92140', 'http://www.journaldelenvironnement.net/article/microplastiques-le-royaume-uni-alimente-l-ocean-arctique,72324', 'http://www.journaldelenvironnement.net/article/les-micro-plastiques-affectent-aussi-les-organismes-d-eau-douce,51400', 'http://www.journaldelenvironnement.net/article/des-fontaines-d-eau-contre-les-dechets-plastique,90031']'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2ab4d97f854d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclean_articles_jdle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_info_articles_jdle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink_articles_jdle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#create_json_file(clean_articles_jdle,'jlde','../data/articles/')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-37bd65d4f9b9>\u001b[0m in \u001b[0;36mget_info_articles_jdle\u001b[1;34m(link_articles)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m# Get title\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"articleTitre\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"articleTitre\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "clean_articles_jdle = get_info_articles_jdle(link_articles_jdle)\n",
    "#create_json_file(clean_articles_jdle,'jlde','../data/articles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le Monde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_articles_lmde(soup_link_website, article_link, start, end):\n",
    "    \"\"\"\n",
    "        Based on the links passed in parameter, we get the url articles of the website\n",
    "        @return :  A list of links of articles\n",
    "    \"\"\"\n",
    "    link_articles = []\n",
    "    key_words = ['plastique','microplastique']\n",
    "    # Get all pages of the website\n",
    "    for i in tqdm_notebook(range(start,end)):\n",
    "        try:\n",
    "            # Get all articles in a page\n",
    "            soup = parse_soup(soup_link_website + str(i) + '.html')\n",
    "            \n",
    "            #Select only the link of the articles\n",
    "            for bal in soup.find_all('h3',{\"class\":\" \"}):\n",
    "                link = bal.find('a').get('href')\n",
    "                if link != None and 'article' in link and any(word in link for word in key_words):\n",
    "                    new_article = article_link + link\n",
    "                    link_articles.append(new_article)\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(e,bal)\n",
    "    \n",
    "    return list(set(link_articles))\n",
    "\n",
    "\n",
    "def get_info_articles_lmde(link_articles):\n",
    "    \"\"\"\n",
    "        We get the content of the different articles\n",
    "        @return ! dictionnary with the sentences by articles\n",
    "    \"\"\"\n",
    "    new_articles = []\n",
    "    for index,link in tqdm_notebook(enumerate(link_articles)):\n",
    "        # Initilialize variables\n",
    "        contents = []\n",
    "        description = title = pub_date = authors = \"\"\n",
    "        \n",
    "        # Get the content of the page relative to an article\n",
    "        soup = parse_soup(link)\n",
    "\n",
    "        # Get the description\n",
    "        if soup.find('p',{\"class\":\"article__desc\"}) != None:\n",
    "            description= soup.find('p',{\"class\":\"article__desc\"}).text\n",
    "\n",
    "        # Get title\n",
    "        if soup.find('h1',{\"class\":\"article_title\"}) != None:\n",
    "                title = soup.find('h1',{\"class\":\"article_title\"}).text\n",
    "\n",
    "        # Get publication date\n",
    "        pub_date = link[40:50]\n",
    "\n",
    "        # Get the authors\n",
    "        if soup.find('span',{\"class\":\"meta__author\"}) != None:\n",
    "            authors = soup.find('span',{\"class\":\"meta__author\"}).text\n",
    "\n",
    "        # Get contents   \n",
    "        if soup.find(\"section\", {\"class\":\"article__content\"}) != None:\n",
    "            article_content = soup.find(\"section\", {\"class\":\"article__content\"})\n",
    "        for content in article_content.find_all('p'):\n",
    "            if content != None:\n",
    "                contents.append(content.text)    \n",
    "        \n",
    "        # Clean the string variable\n",
    "        contents = clean_text(' '.join(contents))\n",
    "        title = clean_text(title)\n",
    "        description = clean_text(description)\n",
    "        authors = clean_text(authors)\n",
    "        \n",
    "        new_articles.append({\n",
    "            \"id_article\":index,\n",
    "            \"link\":link,\n",
    "            \"title\":title,\n",
    "            \"description\":description,\n",
    "            \"content\":contents,\n",
    "            \"authors\":authors,\n",
    "            \"publication_date\":pub_date\n",
    "        })\n",
    "    return new_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> On dans un premier temps avec n pages (selectionnées) sur la catégorie planète du journal le monde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"https://www.lemonde.fr/\"\n",
    "path = '../data/links/url_articles_lmde.csv'\n",
    "lmde_articles = []\n",
    "start_page = 1\n",
    "end_page=20 # choisir un nombre qui fonctionne\n",
    "\n",
    "link_articles_lmde = get_url_articles_lmde(link+'planete/',link,start_page,end_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> On récupère les liens jugées utiles, puis on place le contenu de chaque article dans un fichier json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clean_articles_lmde = get_info_articles_lmde(link_articles_lmde)\n",
    "create_json_file(clean_articles_lmde,'lmde','../data/articles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create csv files to keep the url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jounral de l'environnement\n",
    "pd.DataFrame(link_articles_jdle).to_csv('../data/links/',sep=';')\n",
    "\n",
    "# Le Monde\n",
    "pd.DataFrame(link_articles_lmde).to_csv('../data/links/',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
