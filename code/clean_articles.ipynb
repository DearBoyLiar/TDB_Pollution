{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*\n",
    "import pandas as pd\n",
    "import io\n",
    "from unidecode import unidecode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter des contraintes pour clean le text encore mieux\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        Allow us to clean the text passed in parameter \n",
    "        with the help of word_tokenize method taken from nltk library\n",
    "        @param text : the text to clean\n",
    "        @return : a cleaned text\n",
    "    \"\"\"\n",
    "    return ' '.join(word_tokenize(unidecode(text)))\n",
    "\n",
    "def create_json_file(articles,name,path):\n",
    "    \"\"\"\n",
    "        Transform the list containing info on articles into json file\n",
    "        @param articles : all cleaned articles \n",
    "        @param i : the clean article id\n",
    "        @param path : path where the json files are stored\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame(articles)\n",
    "        filename = 'clean_art_' + name+'.json'\n",
    "        with open(path + filename, 'w', encoding='utf-8') as file:\n",
    "            df.to_json(file,force_ascii=False) \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Journal de l'environnnement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scraped articles\n",
    "articles_jdle = json.loads(io.open('../data/articles/rough_art_jdle.json', 'r', encoding='utf-8-sig').read())\n",
    "\n",
    "# Clean content,description and title element for jdle articles\n",
    "for i in articles_jdle:\n",
    "    articles_jdle[str(i)]['content'] = clean_text(articles_jdle[str(i)]['content'])\n",
    "    articles_jdle[str(i)]['description'] = clean_text(articles_jdle[str(i)]['description'])\n",
    "    articles_jdle[str(i)]['title'] = clean_text(articles_jdle[str(i)]['title'])\n",
    "    \n",
    "# Cleaned articles\n",
    "clean_articles_jdle = articles_jdle\n",
    "create_json_file(clean_articles_jdle,'jdle','../data/articles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le Monde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scraped articles\n",
    "articles_lmde = json.loads(io.open('../data/articles/rough_art_lmde.json', 'r', encoding='utf-8-sig').read())\n",
    "\n",
    "# Clean content,description and title element for jdle articles\n",
    "for i in articles_jdle:\n",
    "    articles_lmde[str(i)]['content'] = clean_text(articles_lmde[str(i)]['content'])\n",
    "    articles_lmde[str(i)]['description'] = clean_text(articles_lmde[str(i)]['description'])\n",
    "    articles_lmde[str(i)]['title'] = clean_text(articles_lmde[str(i)]['title'])\n",
    "    \n",
    "# Cleaned articles\n",
    "clean_articles_lmde = articles_lmde\n",
    "create_json_file(clean_articles_lmde,'lmde','../data/articles/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7eme Continent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scraped articles\n",
    "articles_7econ = json.loads(io.open('../data/articles/rough_art_7econ.json', 'r', encoding='utf-8-sig').read())\n",
    "\n",
    "# Clean content,descirotion and title element for jdle articles\n",
    "for i in articles_jdle:\n",
    "    if int(i) < 135:\n",
    "        articles_7econ[str(i)]['content'] = clean_text(articles_7econ[str(i)]['content'])\n",
    "        articles_7econ[str(i)]['title'] = clean_text(articles_7econ[str(i)]['title'])\n",
    "    \n",
    "# Cleaned articles\n",
    "clean_articles_7econ = articles_7econ\n",
    "create_json_file(clean_articles_7econ,'7econ','../data/articles/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
